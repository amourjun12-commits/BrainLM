import { useState, useRef, useCallback } from 'react'

export const useVoiceRecorder = () => {
  const [isRecording, setIsRecording] = useState(false)
  const [audioBlob, setAudioBlob] = useState(null)
  const [audioUrl, setAudioUrl] = useState(null)
  const [transcription, setTranscription] = useState('')
  const [isTranscribing, setIsTranscribing] = useState(false)
  const [error, setError] = useState(null)
  const [recordingStartTime, setRecordingStartTime] = useState(null)
  const mediaRecorderRef = useRef(null)
  const audioChunksRef = useRef([])
  const streamRef = useRef(null)

  const startRecording = useCallback(async () => {
    try {
      setError(null)
      console.log('ðŸš€ DÃ©marrage de l\'enregistrement...')
      
      // VÃ©rifier si l'API est supportÃ©e
      if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        throw new Error('L\'enregistrement audio n\'est pas supportÃ© sur ce navigateur')
      }

      // VÃ©rifier si on est en HTTPS (requis pour getUserMedia)
      if (window.location.protocol !== 'https:' && window.location.hostname !== 'localhost') {
        throw new Error('L\'enregistrement audio nÃ©cessite une connexion HTTPS')
      }

      console.log('ðŸ“¡ Demande d\'accÃ¨s au microphone...')
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          sampleRate: 44100
        } 
      })
      
      console.log('âœ… AccÃ¨s au microphone accordÃ©')
      streamRef.current = stream
      
      // DÃ©terminer le meilleur format audio supportÃ©
      const mimeTypes = [
        'audio/webm;codecs=opus',
        'audio/webm',
        'audio/mp4',
        'audio/ogg;codecs=opus',
        'audio/wav'
      ]
      
      let selectedMimeType = null
      for (const mimeType of mimeTypes) {
        if (MediaRecorder.isTypeSupported(mimeType)) {
          selectedMimeType = mimeType
          break
        }
      }
      
      if (!selectedMimeType) {
        throw new Error('Aucun format audio supportÃ© trouvÃ©')
      }
      
      console.log('ðŸŽµ Format audio sÃ©lectionnÃ©:', selectedMimeType)
      
      mediaRecorderRef.current = new MediaRecorder(stream, {
        mimeType: selectedMimeType
      })
      
      audioChunksRef.current = []
      setRecordingStartTime(Date.now())

      mediaRecorderRef.current.ondataavailable = (event) => {
        console.log('ðŸ“¦ DonnÃ©es audio reÃ§ues:', event.data.size, 'bytes')
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data)
        }
      }

      mediaRecorderRef.current.onstop = () => {
        console.log('â¹ï¸ Enregistrement arrÃªtÃ©, traitement des donnÃ©es...')
        if (audioChunksRef.current.length > 0) {
          const totalSize = audioChunksRef.current.reduce((sum, chunk) => sum + chunk.size, 0)
          console.log('ðŸ“Š Taille totale des donnÃ©es:', totalSize, 'bytes')
          
          const blob = new Blob(audioChunksRef.current, { 
            type: mediaRecorderRef.current.mimeType 
          })
          console.log('ðŸŽµ Blob audio crÃ©Ã©:', blob.size, 'bytes, type:', blob.type)
          
          setAudioBlob(blob)
          const url = URL.createObjectURL(blob)
          setAudioUrl(url)
          console.log('ðŸ”— URL audio crÃ©Ã©e:', url)
        } else {
          console.warn('âš ï¸ Aucune donnÃ©e audio reÃ§ue')
        }
        
        // ArrÃªter tous les tracks du stream
        if (streamRef.current) {
          streamRef.current.getTracks().forEach(track => {
            console.log('ðŸ›‘ ArrÃªt du track:', track.kind)
            track.stop()
          })
          streamRef.current = null
        }
      }

      mediaRecorderRef.current.onerror = (event) => {
        console.error('âŒ Erreur MediaRecorder:', event.error)
        setError('Erreur lors de l\'enregistrement audio: ' + event.error.message)
        setIsRecording(false)
      }

      mediaRecorderRef.current.onstart = () => {
        console.log('ðŸŽ™ï¸ Enregistrement dÃ©marrÃ© avec succÃ¨s')
      }

      console.log('â–¶ï¸ DÃ©marrage de l\'enregistrement...')
      mediaRecorderRef.current.start(1000) // Collecter les donnÃ©es toutes les secondes
      setIsRecording(true)
      console.log('âœ… Enregistrement en cours')
    } catch (error) {
      console.error('âŒ Erreur lors du dÃ©marrage de l\'enregistrement:', error)
      
      let errorMessage = 'Impossible d\'accÃ©der au microphone'
      
      if (error.name === 'NotAllowedError') {
        errorMessage = 'AccÃ¨s au microphone refusÃ©. Veuillez autoriser l\'accÃ¨s dans les paramÃ¨tres de votre navigateur.'
      } else if (error.name === 'NotFoundError') {
        errorMessage = 'Aucun microphone trouvÃ©. Veuillez connecter un microphone.'
      } else if (error.name === 'NotSupportedError') {
        errorMessage = 'L\'enregistrement audio n\'est pas supportÃ© sur ce navigateur.'
      } else if (error.message.includes('HTTPS')) {
        errorMessage = 'L\'enregistrement audio nÃ©cessite une connexion HTTPS sÃ©curisÃ©e.'
      } else {
        errorMessage = `Erreur: ${error.message}`
      }
      
      setError(errorMessage)
      setIsRecording(false)
    }
  }, [])

  const stopRecording = useCallback(() => {
    console.log('ðŸ›‘ Demande d\'arrÃªt de l\'enregistrement...')
    if (mediaRecorderRef.current && isRecording) {
      try {
        console.log('â¹ï¸ ArrÃªt de l\'enregistrement...')
        mediaRecorderRef.current.stop()
        setIsRecording(false)
        console.log('âœ… Enregistrement arrÃªtÃ©')
      } catch (error) {
        console.error('âŒ Erreur lors de l\'arrÃªt de l\'enregistrement:', error)
        setError('Erreur lors de l\'arrÃªt de l\'enregistrement: ' + error.message)
        setIsRecording(false)
      }
    } else {
      console.warn('âš ï¸ Tentative d\'arrÃªt sans enregistrement en cours')
    }
  }, [isRecording])

  const transcribeAudio = useCallback(async () => {
    if (!audioBlob) {
      console.warn('âš ï¸ Aucun audio Ã  transcrire')
      return
    }

    console.log('ðŸŽ¤ DÃ©but de la transcription...')
    setIsTranscribing(true)
    setError(null)
    
    try {
      // Simulation de transcription (dans une vraie app, vous utiliseriez une API comme OpenAI Whisper)
      console.log('â³ Simulation de transcription en cours...')
      await new Promise(resolve => setTimeout(resolve, 2000))
      
      const mockTranscription = "Ceci est une transcription simulÃ©e de votre enregistrement vocal. Dans une version complÃ¨te, cette fonctionnalitÃ© utiliserait l'API Whisper d'OpenAI pour transcrire automatiquement votre audio en texte."
      setTranscription(mockTranscription)
      console.log('âœ… Transcription simulÃ©e terminÃ©e')
    } catch (error) {
      console.error('âŒ Erreur lors de la transcription:', error)
      setError('Erreur lors de la transcription audio: ' + error.message)
    } finally {
      setIsTranscribing(false)
    }
  }, [audioBlob])

  const clearRecording = useCallback(() => {
    console.log('ðŸ—‘ï¸ Nettoyage de l\'enregistrement...')
    setAudioBlob(null)
    setAudioUrl(null)
    setTranscription('')
    setError(null)
    audioChunksRef.current = []
    setRecordingStartTime(null)
    
    // Nettoyer l'URL crÃ©Ã©e
    if (audioUrl) {
      URL.revokeObjectURL(audioUrl)
      console.log('ðŸ”— URL audio nettoyÃ©e')
    }
  }, [audioUrl])

  const getRecordingDuration = useCallback(() => {
    if (!recordingStartTime || !isRecording) return 0
    return Math.floor((Date.now() - recordingStartTime) / 1000)
  }, [recordingStartTime, isRecording])

  return {
    isRecording,
    audioBlob,
    audioUrl,
    transcription,
    isTranscribing,
    error,
    startRecording,
    stopRecording,
    transcribeAudio,
    clearRecording,
    getRecordingDuration
  }
}
